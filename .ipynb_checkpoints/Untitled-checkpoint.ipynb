{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14cdbfa2-28be-4490-bf7e-930c2b0f54f4",
   "metadata": {},
   "source": [
    "## Legal document analysis and Q&A using  RAG framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fedf3e5-e0b0-4c44-b8e5-5fe6c90360b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (MATCHES YOUR VERSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56951408-7144-49e3-9316-c905d9e07175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from pypdf import PdfReader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3bbebc2-40ca-4704-a4b3-512cd4d125c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Legal PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6153e18-c40a-4c63-bc87-bbc75c535622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 legal documents\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"legal_docs\"  # Folder containing your PDFs\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file in os.listdir(DATA_DIR):\n",
    "    if file.lower().endswith(\".pdf\"):\n",
    "        reader = PdfReader(os.path.join(DATA_DIR, file))\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text\n",
    "        \n",
    "        documents.append({\n",
    "            \"text\": text,\n",
    "            \"source\": file\n",
    "        })\n",
    "\n",
    "print(f\"Loaded {len(documents)} legal documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22e75ca-dd24-46e3-b33d-5976f8043413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Chunking (Legal-Friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eafb9823-474a-4ead-a7a5-11d0f4e76308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text chunks created: 4\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        texts.append(chunk)\n",
    "        metadatas.append({\"source\": doc[\"source\"]})\n",
    "\n",
    "print(f\"Total text chunks created: {len(texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df15a52b-e182-4c33-9f35-cd077fdce765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Model (Sentence-Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2015c6e4-cada-4055-996f-b385bd5d676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFTransformerEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            inputs = self.tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "                embeddings.append(embedding.squeeze().numpy())\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "        return embedding.squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10368b4f-26b3-4ede-8243-815fc92a0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43febaa5-707f-450c-8da0-9da0a7e66a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HFTransformerEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b945af8f-0334-4653-96f6-95e9391b3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fe83433-3124-4dfb-b84e-606e73c1daf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created and saved\n"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embedding_model,\n",
    "    metadatas=metadatas\n",
    ")\n",
    "\n",
    "vectorstore.save_local(\"faiss_legal_index\")\n",
    "print(\"FAISS index created and saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36aa1656-8658-40e6-bee1-9d0eb46c2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# . Load FAISS Index (Reusable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e27e4f96-104b-4c4d-8ee1-4c3594021e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded successfully\n"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.load_local(\n",
    "    \"faiss_legal_index\",\n",
    "    embedding_model\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}\n",
    ")\n",
    "\n",
    "print(\"FAISS index loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c7be326-5567-4c97-bf90-46e9bb23a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Open-Source LLM (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "303748e6-ad51-4bba-b8b8-6e778b412f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a933b3a-7fac-4fa2-b1eb-173380153d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RAG QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "362ab99f-0ed6-4445-8e2e-2189760be0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1777816-a553-4936-85a0-189d36a087de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask Legal Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82004bba-7e4f-46a9-88a1-41db7dcb3a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "30 days written notice\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "- Employment_Contract.pdf\n",
      "- Service_Agreement.pdf\n",
      "- Non_Disclosure_Agreement.pdf\n",
      "- Privacy_Policy.pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the termination conditions mentioned in the contract?\"\n",
    "\n",
    "response = qa_chain(query)\n",
    "\n",
    "print(\"Answer:\\n\")\n",
    "print(response[\"result\"])\n",
    "\n",
    "print(\"\\nSource Documents:\\n\")\n",
    "for doc in response[\"source_documents\"]:\n",
    "    print(\"-\", doc.metadata[\"source\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "502fafb5-1b59-4057-8d95-09d6ca70b483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Legal Document Q&A Chat (RAG System)\n",
      "Type your legal question and press Enter\n",
      "Type 'exit' or 'quit' to end the session\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Legal Question >  What are the termination conditions?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "30 days written notice\n",
      "\n",
      "Source Documents:\n",
      "- Non_Disclosure_Agreement.pdf\n",
      "- Employment_Contract.pdf\n",
      "- Privacy_Policy.pdf\n",
      "- Service_Agreement.pdf\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Legal Question >  what is the limitation of liability?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Liability shall not exceed the total contract value.\n",
      "\n",
      "Source Documents:\n",
      "- Non_Disclosure_Agreement.pdf\n",
      "- Employment_Contract.pdf\n",
      "- Privacy_Policy.pdf\n",
      "- Service_Agreement.pdf\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Legal Question >  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session ended. Thank you.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "216471e3-cbc5-44b4-9336-4267da73adf6",
   "metadata": {},
   "source": [
    "ðŸ“˜ Legal Document Q&A Chat (RAG System)\n",
    "\n",
    "Legal Question > What are the termination conditions?\n",
    "\n",
    "Answer:\n",
    "Either party may terminate the agreement with 30 days written notice...\n",
    "\n",
    "Source Documents:\n",
    "- Employment_Contract.pdf\n",
    "------------------------------------------------------------\n",
    "\n",
    "Legal Question > What is the limitation of liability?\n",
    "\n",
    "Answer:\n",
    "The liability shall not exceed the total contract value...\n",
    "\n",
    "Source Documents:\n",
    "- Service_Agreement.pdf\n",
    "------------------------------------------------------------\n",
    "\n",
    "Legal Question > exit\n",
    "\n",
    "Session ended. Thank you.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
